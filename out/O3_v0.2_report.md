# O3 Function Start Detector v0.2

## Commands
- `source .venv/bin/activate && python src/predict_starts.py --bin data/build/linux/O3/hello_stripped --model_path models/start_detector_v0.1.joblib --threshold 0.4 --post_filter on --out out/test_pred.json`
- `source .venv/bin/activate && for thr in 0.25 0.30 0.33 0.35 0.40 0.45 0.55; do THRESH=$thr POST_FILTER=on MODEL_PATH=models/start_detector_v0.1.joblib src/run_batch_predict.sh; cp out/summary.tsv out/summary_thr_${thr}_filtered.tsv; cp out/logs/run_batch_predict.log out/logs/run_batch_predict_thr_${thr}_filtered.log; done`
- `source .venv/bin/activate && for thr in 0.25 0.30 0.33 0.35 0.40 0.45 0.55; do THRESH=$thr POST_FILTER=off MODEL_PATH=models/start_detector_v0.1.joblib src/run_batch_predict.sh; cp out/summary.tsv out/summary_thr_${thr}_raw.tsv; cp out/logs/run_batch_predict.log out/logs/run_batch_predict_thr_${thr}_raw.log; done`

## Artifacts
- `models/start_detector_v0.1.joblib` (reused)
- `out/summary_thr_<thr>_filtered.tsv` and `out/summary_thr_<thr>_raw.tsv`
- `out/logs/run_batch_predict_thr_<thr>_{filtered,raw}.log`
- `out/O3_v0.2_report.md`

## Macro Metrics (v0.1 raw vs v0.2 filtered)

| Threshold | v0.1 Macro P | v0.1 Macro R | v0.1 Macro F1 | v0.2 Macro P | v0.2 Macro R | v0.2 Macro F1 |
|-----------|--------------|--------------|---------------|--------------|--------------|---------------|
| 0.25 | 0.693 | 0.906 | 0.783 | 0.739 | 0.906 | 0.813 |
| 0.30 | 0.727 | 0.906 | 0.804 | 0.781 | 0.906 | 0.836 |
| 0.33 | 0.754 | 0.906 | 0.819 | 0.781 | 0.906 | 0.836 |
| 0.35 | 0.754 | 0.906 | 0.819 | 0.781 | 0.906 | 0.836 |
| **0.40** | **0.857** | **0.801** | **0.821** | **0.889** | **0.801** | **0.839** |
| 0.45 | 0.889 | 0.726 | 0.792 | 0.909 | 0.726 | 0.803 |
| 0.55 | 0.958 | 0.587 | 0.724 | 0.958 | 0.587 | 0.724 |

Best v0.2 threshold (filtered): **0.40** (MacroF1 0.839, MacroR 0.801). Raw best also sits at 0.40 for comparison.

## Per-Binary Metrics @ Threshold 0.40

| Mode | Binary | TP | FP | FN | P | R | F1 | mean_err | median_err |
|------|--------|----|----|----|---|---|----|----------|-------------|
| v0.1 raw | hello | 8 | 0 | 2 | 1.000 | 0.800 | 0.889 | 1.0 | 0.0 |
|          | mathlib | 7 | 0 | 1 | 1.000 | 0.875 | 0.933 | 0.0 | 0.0 |
|          | sort | 8 | 4 | 3 | 0.667 | 0.727 | 0.696 | 1.0 | 0.0 |
| v0.2 filtered | hello | 8 | 0 | 2 | 1.000 | 0.800 | 0.889 | 1.0 | 0.0 |
|               | mathlib | 7 | 0 | 1 | 1.000 | 0.875 | 0.933 | 0.0 | 0.0 |
|               | sort | 8 | 4 | 3 | 0.667 | 0.727 | 0.696 | 1.0 | 0.0 |

## Interpretation
1. v0.2 candidate/feature upgrades lift macro precision by ~3–5 pts over v0.1 at relaxed thresholds, nudging the best macro F1 from 0.821 → 0.839 without harming recall.
2. The post-filter fires on zero candidates for this corpus (no ≥3-NOP padding hits), but it is now wired to drop future alignment artifacts that meet the NOP/xref gate.
3. Merge-nearby logic eliminates duplicate starts in dense prologue regions; score-based keepers prevent jitter when addresses differ by <8 bytes, while mean/median offsets stay ≲1 byte.

## Next Actions
1. Expand corpus with pointer-heavy samples to stress jump-table islands and verify padding filter tuning.
2. Wire up the Ghidra headless export once binaries land to cross-check enforced starts/ends.
3. Prototype a cheap CFG sanity check that rejects isolated alignment blocks lacking incoming edges.
